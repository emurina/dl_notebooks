{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis_1D_conv_LSTMs_attention",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bmhRRItg27b",
        "colab_type": "text"
      },
      "source": [
        "## Different models for  sentiment analysis on the  IMDb Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9AbM8bYk5bG",
        "colab_type": "code",
        "outputId": "1af2bc70-0391-4a94-f42a-efd1ad9e5e89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrrFlTkVo2gb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXpqAr5Dg27d",
        "colab_type": "code",
        "outputId": "afcc6176-8c73-42c7-86a8-56e307723780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df = pd.read_csv('/content/drive/My Drive/Masterarbeit_Elvis/movie_data.csv', encoding='utf-8')\n",
        "df.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I went and saw this movie last night after bei...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>As a recreational golfer with some knowledge o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  I went and saw this movie last night after bei...          1\n",
              "1  Actor turned director Bill Paxton follows up h...          1\n",
              "2  As a recreational golfer with some knowledge o...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UMgi0G1g27t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = df.loc[:24999, 'review'].values\n",
        "y_train = df.loc[:24999, 'sentiment'].values\n",
        "X_test = df.loc[25000:, 'review'].values\n",
        "y_test = df.loc[25000:, 'sentiment'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUwCLQ5xg27x",
        "colab_type": "code",
        "outputId": "32aeb9d6-ea92-4179-8ffd-55994b0272fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "for i in range(0,5):\n",
        "    print(X_train[i])\n",
        "    print(\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000,)\n",
            "I went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit that I was reluctant to see it because from what I knew of Ashton Kutcher he was only able to do comedy. I was wrong. Kutcher played the character of Jake Fischer very well, and Kevin Costner played Ben Randall with such professionalism. The sign of a good movie is that it can toy with our emotions. This one did exactly that. The entire theater (which was sold out) was overcome by laughter during the first half of the movie, and were moved to tears during the second half. While exiting the theater I not only saw many women in tears, but many full grown men as well, trying desperately not to let anyone see them crying. This movie was great, and I suggest that you go see it before you judge.\n",
            "\n",
            "Actor turned director Bill Paxton follows up his promising debut, the Gothic-horror \"Frailty\", with this family friendly sports drama about the 1913 U.S. Open where a young American caddy rises from his humble background to play against his Bristish idol in what was dubbed as \"The Greatest Game Ever Played.\" I'm no fan of golf, and these scrappy underdog sports flicks are a dime a dozen (most recently done to grand effect with \"Miracle\" and \"Cinderella Man\"), but some how this film was enthralling all the same.<br /><br />The film starts with some creative opening credits (imagine a Disneyfied version of the animated opening credits of HBO's \"Carnivale\" and \"Rome\"), but lumbers along slowly for its first by-the-numbers hour. Once the action moves to the U.S. Open things pick up very well. Paxton does a nice job and shows a knack for effective directorial flourishes (I loved the rain-soaked montage of the action on day two of the open) that propel the plot further or add some unexpected psychological depth to the proceedings. There's some compelling character development when the British Harry Vardon is haunted by images of the aristocrats in black suits and top hats who destroyed his family cottage as a child to make way for a golf course. He also does a good job of visually depicting what goes on in the players' heads under pressure. Golf, a painfully boring sport, is brought vividly alive here. Credit should also be given the set designers and costume department for creating an engaging period-piece atmosphere of London and Boston at the beginning of the twentieth century.<br /><br />You know how this is going to end not only because it's based on a true story but also because films in this genre follow the same template over and over, but Paxton puts on a better than average show and perhaps indicates more talent behind the camera than he ever had in front of it. Despite the formulaic nature, this is a nice and easy film to root for that deserves to find an audience.\n",
            "\n",
            "As a recreational golfer with some knowledge of the sport's history, I was pleased with Disney's sensitivity to the issues of class in golf in the early twentieth century. The movie depicted well the psychological battles that Harry Vardon fought within himself, from his childhood trauma of being evicted to his own inability to break that glass ceiling that prevents him from being accepted as an equal in English golf society. Likewise, the young Ouimet goes through his own class struggles, being a mere caddie in the eyes of the upper crust Americans who scoff at his attempts to rise above his standing. <br /><br />What I loved best, however, is how this theme of class is manifested in the characters of Ouimet's parents. His father is a working-class drone who sees the value of hard work but is intimidated by the upper class; his mother, however, recognizes her son's talent and desire and encourages him to pursue his dream of competing against those who think he is inferior.<br /><br />Finally, the golf scenes are well photographed. Although the course used in the movie was not the actual site of the historical tournament, the little liberties taken by Disney do not detract from the beauty of the film. There's one little Disney moment at the pool table; otherwise, the viewer does not really think Disney. The ending, as in \"Miracle,\" is not some Disney creation, but one that only human history could have written.\n",
            "\n",
            "I saw this film in a sneak preview, and it is delightful. The cinematography is unusually creative, the acting is good, and the story is fabulous. If this movie does not do well, it won't be because it doesn't deserve to. Before this film, I didn't realize how charming Shia Lebouf could be. He does a marvelous, self-contained, job as the lead. There's something incredibly sweet about him, and it makes the movie even better. The other actors do a good job as well, and the film contains moments of really high suspense, more than one might expect from a movie about golf. Sports movies are a dime a dozen, but this one stands out. <br /><br />This is one I'd recommend to anyone.\n",
            "\n",
            "Bill Paxton has taken the true story of the 1913 US golf open and made a film that is about much more than an extra-ordinary game of golf. The film also deals directly with the class tensions of the early twentieth century and touches upon the profound anti-Catholic prejudices of both the British and American establishments. But at heart the film is about that perennial favourite of triumph against the odds.<br /><br />The acting is exemplary throughout. Stephen Dillane is excellent as usual, but the revelation of the movie is Shia LaBoeuf who delivers a disciplined, dignified and highly sympathetic performance as a working class Franco-Irish kid fighting his way through the prejudices of the New England WASP establishment. For those who are only familiar with his slap-stick performances in \"Even Stevens\" this demonstration of his maturity is a delightful surprise. And Josh Flitter as the ten year old caddy threatens to steal every scene in which he appears.<br /><br />A old fashioned movie in the best sense of the word: fine acting, clear directing and a great story that grips to the end - the final scene an affectionate nod to Casablanca is just one of the many pleasures that fill a great movie.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNorts6Ig273",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.concatenate((X_train, X_test), axis=0)\n",
        "y = np.concatenate((y_train, y_test), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqUBSAmxg277",
        "colab_type": "code",
        "outputId": "ed0a6e7b-51fe-4ae1-bea0-0a845fb625a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# summarize size\n",
        "print(\"Training data: \")\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data: \n",
            "(50000,)\n",
            "(50000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVWv43X2g28B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "tokenizer_obj = Tokenizer()\n",
        "total_reviews = X_train + X_test\n",
        "tokenizer_obj.fit_on_texts(total_reviews) \n",
        "\n",
        "# pad sequences\n",
        "max_length = max([len(s.split()) for s in total_reviews])\n",
        "\n",
        "# define vocabulary size\n",
        "vocab_size = len(tokenizer_obj.word_index) + 1\n",
        "\n",
        "X_train_tokens =  tokenizer_obj.texts_to_sequences(X_train)\n",
        "X_test_tokens = tokenizer_obj.texts_to_sequences(X_test)\n",
        "\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_tokens, maxlen=max_length, padding='pre')\n",
        "X_test_pad = pad_sequences(X_test_tokens, maxlen=max_length, padding='pre')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMTc8ZOwg28H",
        "colab_type": "code",
        "outputId": "f47a403c-62fd-43d8-bfb0-8212ab367674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "125602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS0Dnt01g28P",
        "colab_type": "code",
        "outputId": "50ce4e24-2e42-4781-8941-d156cb812807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(X_train_pad.shape)\n",
        "print(X_train_pad[0])#just numers now"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 2678)\n",
            "[   0    0    0 ...  158   22 1717]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOovPAENg28W",
        "colab_type": "code",
        "outputId": "f637befa-a643-4845-ce24-1289893ee7f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, GRU, Conv1D, GlobalAveragePooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "EMBEDDING_DIM = 50\n",
        "\n",
        "print('Build model...')\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, EMBEDDING_DIM, input_length=max_length))\n",
        "model.add(Conv1D(filters=50,kernel_size=(40)))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print('Summary of the built model...')\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "Summary of the built model...\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 2678, 50)          6280100   \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 2639, 50)          100050    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_2 ( (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 6,380,201\n",
            "Trainable params: 6,380,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLDfMvvJg28e",
        "colab_type": "code",
        "outputId": "e3f106b3-f20f-437c-c045-afd6dccfaf81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 2678, 50)          6280100   \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 2639, 50)          100050    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_2 ( (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 6,380,201\n",
            "Trainable params: 6,380,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI-6Jnl_g28k",
        "colab_type": "code",
        "outputId": "ffb7c6d3-b118-424b-d1c0-07ed78bacd6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(max_length)\n",
        "print(vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2678\n",
            "125602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlgvP7n7g28q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G8c6KqSg28z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(22)\n",
        "idx=np.random.choice(range(0,25000),replace=False,size=20000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V5o-Zk9g287",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_pad =X_train_pad[idx] \n",
        "y_train=y_train[idx] \n",
        "X_test_pad=X_test_pad[idx] \n",
        "y_test=y_test[idx] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkQKmSSrg28_",
        "colab_type": "code",
        "outputId": "21888040-7e02-417d-a92e-2268ff662e9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train_pad[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0, ...,   48,   22, 1371], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZp8t3fig29U",
        "colab_type": "code",
        "outputId": "db470659-d183-46b5-ae22-bc41341b27c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "print('Train...')\n",
        "\n",
        "model.fit(X_train_pad, y_train, batch_size=64, epochs=10, validation_data=(X_test_pad, y_test), verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Train on 20000 samples, validate on 20000 samples\n",
            "Epoch 1/10\n",
            "20000/20000 [==============================] - 12s 606us/step - loss: 0.6136 - acc: 0.6306 - val_loss: 0.4122 - val_acc: 0.8154\n",
            "Epoch 2/10\n",
            "20000/20000 [==============================] - 12s 579us/step - loss: 0.2949 - acc: 0.8794 - val_loss: 0.4000 - val_acc: 0.8256\n",
            "Epoch 3/10\n",
            "20000/20000 [==============================] - 12s 586us/step - loss: 0.1958 - acc: 0.9212 - val_loss: 0.3317 - val_acc: 0.8790\n",
            "Epoch 4/10\n",
            "20000/20000 [==============================] - 12s 580us/step - loss: 0.1325 - acc: 0.9490 - val_loss: 0.4081 - val_acc: 0.8619\n",
            "Epoch 5/10\n",
            "20000/20000 [==============================] - 11s 572us/step - loss: 0.0970 - acc: 0.9648 - val_loss: 0.4095 - val_acc: 0.8736\n",
            "Epoch 6/10\n",
            "20000/20000 [==============================] - 11s 567us/step - loss: 0.0704 - acc: 0.9729 - val_loss: 0.5243 - val_acc: 0.8527\n",
            "Epoch 7/10\n",
            "20000/20000 [==============================] - 11s 564us/step - loss: 0.0550 - acc: 0.9800 - val_loss: 0.5152 - val_acc: 0.8681\n",
            "Epoch 8/10\n",
            "20000/20000 [==============================] - 11s 564us/step - loss: 0.0413 - acc: 0.9856 - val_loss: 0.6735 - val_acc: 0.8482\n",
            "Epoch 9/10\n",
            "20000/20000 [==============================] - 11s 565us/step - loss: 0.0332 - acc: 0.9878 - val_loss: 0.6848 - val_acc: 0.8538\n",
            "Epoch 10/10\n",
            "20000/20000 [==============================] - 11s 567us/step - loss: 0.0273 - acc: 0.9907 - val_loss: 0.6925 - val_acc: 0.8569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5e5a236a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWhoNcgfoxR2",
        "colab_type": "code",
        "outputId": "9a429289-b32f-4096-8e5d-32f0be97825c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "# summarize history \n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-903a94304287>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlfQNAMGg29j",
        "colab_type": "code",
        "outputId": "99a7509b-374a-4726-d258-c1bbe204f8a1",
        "colab": {}
      },
      "source": [
        "print('Testing...')\n",
        "score, acc = model.evaluate(X_test_pad, y_test, batch_size=128)\n",
        "\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n",
        "\n",
        "print(\"Accuracy: {0:.2%}\".format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing...\n",
            "5000/5000 [==============================] - 26s 5ms/step\n",
            "Test score: 0.6712235076904297\n",
            "Test accuracy: 0.6188\n",
            "Accuracy: 61.88%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJMJhkhTg29q",
        "colab_type": "code",
        "outputId": "69dd9111-29dd-458e-d2de-8858c964a17f",
        "colab": {}
      },
      "source": [
        "#Let us test some  samples\n",
        "test_sample_1 = \"This movie is fantastic! I really like it because it is so good!\"\n",
        "test_sample_2 = \"Good movie!\"\n",
        "test_sample_3 = \"Maybe I like this movie.\"\n",
        "test_sample_4 = \"Not to my taste, will skip and watch another movie\"\n",
        "test_sample_5 = \"if you like action, then this movie might be good for you.\"\n",
        "test_sample_6 = \"Bad movie!\"\n",
        "test_sample_7 = \"Not a good movie!\"\n",
        "test_sample_8 = \"This movie really sucks! Can I get my money back please?\"\n",
        "test_samples = [test_sample_1, test_sample_2, test_sample_3, test_sample_4, test_sample_5, test_sample_6, test_sample_7, test_sample_8]\n",
        "\n",
        "test_samples_tokens = tokenizer_obj.texts_to_sequences(test_samples)\n",
        "test_samples_tokens_pad = pad_sequences(test_samples_tokens, maxlen=max_length)\n",
        "\n",
        "#predict\n",
        "model.predict(x=test_samples_tokens_pad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5373639 ],\n",
              "       [0.5381622 ],\n",
              "       [0.53790957],\n",
              "       [0.53790396],\n",
              "       [0.53692925],\n",
              "       [0.5380995 ],\n",
              "       [0.5381007 ],\n",
              "       [0.53709775]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ030rLyg29v",
        "colab_type": "code",
        "outputId": "a374b69c-3884-4828-de9c-243d65b14c75",
        "colab": {}
      },
      "source": [
        "#let us check how the model predicts\n",
        "classes = model.predict(X_test_pad[:10], batch_size=128)\n",
        "for i in range (0,10):\n",
        "    if(classes[i] > 0.5 and y_test[i] == 1 or (classes[i] <= 0.5 and y_test[i] == 0)):\n",
        "        print( classes[i], y_test[i], \" Right prdiction\")\n",
        "    else :\n",
        "        print( classes[i], y_test[i], \" Wrong prdiction\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.1360948] 1  Wrong prdiction\n",
            "[0.29261437] 1  Wrong prdiction\n",
            "[0.9970799] 1  Right prdiction\n",
            "[0.87384164] 1  Right prdiction\n",
            "[0.99331176] 1  Right prdiction\n",
            "[0.97243744] 1  Right prdiction\n",
            "[0.85155106] 1  Right prdiction\n",
            "[0.7417877] 1  Right prdiction\n",
            "[0.9908635] 1  Right prdiction\n",
            "[0.9956833] 1  Right prdiction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_zO68dug291",
        "colab_type": "code",
        "outputId": "ab40b69c-0178-44d8-9f78-608b6e011ea3",
        "colab": {}
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from tensorflow.python.keras.preprocessing import sequence\n",
        "from keras.layers import Dense, Embedding, LSTM, GRU\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "# load the dataset but only keep the top n words, zero the rest\n",
        "top_words = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "\n",
        "max_words = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
        "\n",
        "print('Build model...')\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, 100, input_length=max_words))\n",
        "model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 168,353\n",
            "Trainable params: 168,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "yTsNeHJpg29-",
        "colab_type": "code",
        "outputId": "08e6d1aa-e5a1-40e9-89e1-4bf567047caf",
        "colab": {}
      },
      "source": [
        "print('Train...')\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=128, epochs=25, validation_data=(X_test, y_test), verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/25\n",
            " - 513s - loss: 0.1798 - acc: 0.9324 - val_loss: 0.4092 - val_acc: 0.8448\n",
            "Epoch 2/25\n",
            " - 556s - loss: 0.1890 - acc: 0.9283 - val_loss: 0.4166 - val_acc: 0.8473\n",
            "Epoch 3/25\n",
            " - 946s - loss: 0.1736 - acc: 0.9345 - val_loss: 0.4416 - val_acc: 0.8446\n",
            "Epoch 4/25\n",
            " - 651s - loss: 0.1599 - acc: 0.9400 - val_loss: 0.4562 - val_acc: 0.8464\n",
            "Epoch 5/25\n",
            " - 688s - loss: 0.1635 - acc: 0.9390 - val_loss: 0.4382 - val_acc: 0.8432\n",
            "Epoch 6/25\n",
            " - 1021s - loss: 0.1507 - acc: 0.9440 - val_loss: 0.4438 - val_acc: 0.8478\n",
            "Epoch 7/25\n",
            " - 518s - loss: 0.1392 - acc: 0.9476 - val_loss: 0.4582 - val_acc: 0.8507\n",
            "Epoch 8/25\n",
            " - 516s - loss: 0.1573 - acc: 0.9391 - val_loss: 0.4841 - val_acc: 0.8454\n",
            "Epoch 9/25\n",
            " - 785s - loss: 0.1377 - acc: 0.9500 - val_loss: 0.4811 - val_acc: 0.8469\n",
            "Epoch 10/25\n",
            " - 1003s - loss: 0.1353 - acc: 0.9508 - val_loss: 0.4742 - val_acc: 0.8494\n",
            "Epoch 11/25\n",
            " - 630s - loss: 0.1753 - acc: 0.9315 - val_loss: 0.4758 - val_acc: 0.8385\n",
            "Epoch 12/25\n",
            " - 414s - loss: 0.1514 - acc: 0.9414 - val_loss: 0.4896 - val_acc: 0.8444\n",
            "Epoch 13/25\n",
            " - 409s - loss: 0.1239 - acc: 0.9551 - val_loss: 0.5066 - val_acc: 0.8482\n",
            "Epoch 14/25\n",
            " - 403s - loss: 0.1194 - acc: 0.9564 - val_loss: 0.5132 - val_acc: 0.8331\n",
            "Epoch 15/25\n",
            " - 399s - loss: 0.1186 - acc: 0.9569 - val_loss: 0.5432 - val_acc: 0.8396\n",
            "Epoch 16/25\n",
            " - 397s - loss: 0.1159 - acc: 0.9576 - val_loss: 0.5685 - val_acc: 0.8370\n",
            "Epoch 17/25\n",
            " - 398s - loss: 0.1113 - acc: 0.9610 - val_loss: 0.5459 - val_acc: 0.8492\n",
            "Epoch 18/25\n",
            " - 4618s - loss: 0.1527 - acc: 0.9428 - val_loss: 0.5188 - val_acc: 0.8422\n",
            "Epoch 19/25\n",
            " - 428s - loss: 0.1421 - acc: 0.9465 - val_loss: 0.5491 - val_acc: 0.8427\n",
            "Epoch 20/25\n",
            " - 1268s - loss: 0.1138 - acc: 0.9584 - val_loss: 0.5462 - val_acc: 0.8458\n",
            "Epoch 21/25\n",
            " - 2021s - loss: 0.1186 - acc: 0.9570 - val_loss: 0.5658 - val_acc: 0.8437\n",
            "Epoch 22/25\n",
            " - 2063s - loss: 0.1044 - acc: 0.9619 - val_loss: 0.5594 - val_acc: 0.8450\n",
            "Epoch 23/25\n",
            " - 2117s - loss: 0.0954 - acc: 0.9658 - val_loss: 0.5751 - val_acc: 0.8457\n",
            "Epoch 24/25\n",
            " - 2076s - loss: 0.0909 - acc: 0.9688 - val_loss: 0.6008 - val_acc: 0.8440\n",
            "Epoch 25/25\n",
            " - 2485s - loss: 0.0900 - acc: 0.9689 - val_loss: 0.5993 - val_acc: 0.8392\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2ad8e3ad080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nAl5MYBg2-F",
        "colab_type": "code",
        "outputId": "bc812bc8-78bd-4175-b322-45c87bca0d23",
        "colab": {}
      },
      "source": [
        "score, acc = model.evaluate(X_test, y_test, batch_size=128)\n",
        "\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n",
        "print(\"Accuracy: %.2f%%\" % (acc*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 694s 28ms/step\n",
            "Test score: 0.5993069805335999\n",
            "Test accuracy: 0.839160000038147\n",
            "Accuracy: 83.92%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4O1U64Wg2-S",
        "colab_type": "text"
      },
      "source": [
        "The time to train a GRU is less than LSTM network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1qF-3IHg2-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}