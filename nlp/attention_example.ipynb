{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attention_example.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIYTd-kL8j_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Activation,Dense,CuDNNLSTM,LSTM,RepeatVector,Permute,multiply,Lambda, Concatenate, Dropout, Embedding, Conv1D,GlobalMaxPooling1D, Flatten ,MaxPooling1D, GlobalAvgPool1D,BatchNormalization\n",
        "from tensorflow.keras import backend as K\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObAXEUWP8isc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "units = 64\n",
        "max_length = 50\n",
        "vocab_size = 20000\n",
        "embedding_size = 20\n",
        "\n",
        "\n",
        "_input = Input(shape=[max_length], dtype='int32')\n",
        "\n",
        "# get the embedding layer\n",
        "embedded = Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_size,\n",
        "        input_length=max_length,\n",
        "    )(_input)\n",
        "\n",
        "activations = LSTM(units, return_sequences=True)(embedded)\n",
        "\n",
        "# compute importance for each step\n",
        "attention = Dense(1, activation='tanh')(activations) \n",
        "attention = Flatten()(attention)\n",
        "attention = Activation('softmax')(attention)\n",
        "attention = RepeatVector(units)(attention)\n",
        "attention = Permute([2, 1])(attention)\n",
        "\n",
        "# apply the attention\n",
        "sent_representation = multiply([activations, attention])\n",
        "sent_representation = Lambda(lambda xin: K.sum(xin, axis=-1))(sent_representation)\n",
        "#sent_representation = Lambda(lambda xin: K.sum(xin, axis=1))(sent_representation)\n",        
        "#summing up over rows or cols, over rows (axis=1) seems to work better and makes intuitively more sense\n",
        "\n",
        "probabilities = Dense(10, activation='softmax')(sent_representation)\n",
        "\n",
        "model = Model(inputs=_input, outputs=probabilities)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb3XdtmQ8nNm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "outputId": "017d7bfc-32a9-44dd-c85f-11dbd7bff816"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_14 (InputLayer)           [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_13 (Embedding)        (None, 50, 20)       400000      input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_12 (LSTM)                  (None, 50, 64)       21760       embedding_13[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 50, 1)        65          lstm_12[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_11 (Flatten)            (None, 50)           0           dense_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 50)           0           flatten_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_11 (RepeatVector) (None, 64, 50)       0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "permute_11 (Permute)            (None, 50, 64)       0           repeat_vector_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "multiply_6 (Multiply)           (None, 50, 64)       0           lstm_12[0][0]                    \n",
            "                                                                 permute_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 50)           0           multiply_6[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 10)           510         lambda_6[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 422,335\n",
            "Trainable params: 422,335\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAgkPuM0-d68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
